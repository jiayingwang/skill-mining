{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xml.sax.handler import ContentHandler\n",
    "from xml.sax import parse\n",
    "import os\n",
    "paper_tag = ('article','inproceedings','proceedings','book',\n",
    "                   'incollection','phdthesis','mastersthesis')\n",
    "\n",
    "class ResolveHandler(ContentHandler):\n",
    "    \n",
    "    def __init__(self, author_dict, titles):\n",
    "        super().__init__()\n",
    "        self.author_dict = author_dict\n",
    "        self.titles = titles\n",
    "        self.authors = ''\n",
    "        self.title =''\n",
    "        self.count = 0\n",
    "        self.author_flag = False\n",
    "        self.title_flag = False\n",
    "        self.paper_flag = False\n",
    "        \n",
    "    def startElement(self, name, attrs):\n",
    "        if self.paper_flag:\n",
    "            if name == 'author':\n",
    "                self.author_flag = True\n",
    "            elif name == 'title':\n",
    "                self.title_flag = True      \n",
    "        elif name in paper_tag:\n",
    "            self.paper_flag = True\n",
    "                \n",
    "    def endElement(self, name):\n",
    "        if self.paper_flag:\n",
    "            if name == 'author':\n",
    "                self.authors += ','\n",
    "                self.author_flag = False\n",
    "            if name =='title':\n",
    "                self.title_flag = False\n",
    "            if name in paper_tag:\n",
    "                for author in self.authors.split(','):\n",
    "                    if author != '':\n",
    "                        self.author_dict.setdefault(author, []).append(self.count)\n",
    "                self.titles.append(self.title)\n",
    "                if self.count % 100000 == 0:\n",
    "                    print('.', end='')\n",
    "                self.count += 1\n",
    "                self.authors = ''\n",
    "                self.title = ''\n",
    "                self.paper_flag = False\n",
    "        \n",
    "    def characters(self, s):\n",
    "        if self.paper_flag:\n",
    "            if self.author_flag:\n",
    "                self.authors += s\n",
    "            elif self.title_flag:\n",
    "                self.title += s\n",
    "\n",
    "class DBLP:\n",
    "    def __init__(self):\n",
    "        self.authors = {}\n",
    "        self.titles = []\n",
    "        self.default_path = 'dblp_index'\n",
    "        \n",
    "    def load(self, path=None):\n",
    "        if not path:\n",
    "            path = self.default_path\n",
    "        if not os.path.exists(path):\n",
    "            print('Failed to find path ' + path)\n",
    "            return\n",
    "        author_path = os.path.join(path, 'author.dat')\n",
    "        title_path = os.path.join(path, 'title.dat')\n",
    "        \n",
    "        author_file = open(author_path, encoding = 'utf-8')\n",
    "        title_file = open(title_path, encoding = 'utf-8')\n",
    "        for line in author_file:\n",
    "            L = line.split(':')\n",
    "            self.authors[L[0]] = [int(x) for x in L[1].split(',')]\n",
    "        for line in title_file:\n",
    "            self.titles.append(line)\n",
    "        print('done.')\n",
    "            \n",
    "    def search(self, author_name):\n",
    "        titles = []\n",
    "        if author_name in self.authors:\n",
    "            for idx in self.authors[author_name]:\n",
    "                titles.append(self.titles[idx])\n",
    "        return titles\n",
    "        \n",
    "            \n",
    "    def creat_index(self, raw_file='dblp.xml', path=None):\n",
    "        if not os.path.exists(raw_file):\n",
    "            print(raw_file, 'is not found')\n",
    "            return\n",
    "        if not path:\n",
    "            path = self.default_path\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "        author_path = os.path.join(path, 'author.dat')\n",
    "        title_path = os.path.join(path, 'title.dat')\n",
    "        print('parsing dblp.xml', end='')\n",
    "        self.author_dict = {}\n",
    "        self.titles = []\n",
    "        parse(raw_file, ResolveHandler(self.author_dict, self.titles))\n",
    "        print('done.')\n",
    "        print('create index ...', end='')\n",
    "        \n",
    "        author_file = open(author_path, 'w+', encoding='utf-8')\n",
    "        for author in self.author_dict:\n",
    "            author_file.write(author.lower()+':'+ ','.join([str(x) for x in self.author_dict[author]]) + '\\n')\n",
    "        author_file.close()\n",
    "        print('done.')\n",
    "        \n",
    "        title_file = open(title_path, 'w+', encoding='utf-8')\n",
    "        for title in self.titles:\n",
    "            title_file.write(title.lower()+'\\n')\n",
    "        title_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsing dblp.xml................................................done.\n",
      "create index ...done.\n"
     ]
    }
   ],
   "source": [
    "dblp = DBLP()\n",
    "dblp.creat_index()  #创建索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done.\n"
     ]
    }
   ],
   "source": [
    "dblp.load()   #读入索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "please enter a name: jiaying wang\n",
      "12 papers were found.\n",
      "--------------------------------------------------\n",
      "State-of-the-art in string similarity search and join.\n",
      "LS-Join: Local Similarity Join on String Collections.\n",
      "A Novel Resource Allocation and Spectrum Defragmentation Mechanism for IoT-Based Big Data in Smart Cities.\n",
      "LS-Join: Local Similarity Join on String Collections (Extended Abstract).\n",
      "Efficient direct search on compressed genomic data.\n",
      "An Efficient Trip Planning Algorithm under Constraints.\n",
      "Research on Diabetes Management Strategy Based on Deep Belief Network.\n",
      "An improved AdaBoost face detection algorithm based on optimizing skin color model.\n",
      "An Adaptive Approach of Approximate Substring Matching.\n",
      "Reducing Extension Edges of Concurrent Programs for Reachability Analysis.\n",
      "Memory-Aware BWT by Segmenting Sequences to Support Subsequence Search.\n",
      "Cache-aware parallel approximate matching and join algorithms using BWT.\n"
     ]
    }
   ],
   "source": [
    "name = input('please enter a name: ')\n",
    "titles = dblp.search(name.strip().lower())    #函数返回一个放入所查作者的title的列表\n",
    "print(str(len(titles)) + ' papers were found.')\n",
    "print('-'*50)\n",
    "for title in titles:\n",
    "    print(title)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
